# Story: GPU Acceleration for OCR Pipeline

**Status**: Done  
**Created**: 2025-12-10  

## Goal
Leverage the M-series (Metal) GPU/ANE to speed up OCR ensemble runs (especially EasyOCR/torch) while keeping output quality unchanged or better. Ship a “pit of success” default so runs auto-use GPU when available and auto-generate fresh run_ids to avoid stale state.

## Success Criteria
- EasyOCR automatically uses GPU (MPS) on Apple Silicon when available; falls back to CPU otherwise.
- A fresh run_id/output_dir is generated by default unless the user opts in to reuse; long historical timelines are avoided.
- A timing summary is emitted per run (stage wall time + pages/min for extract) so perf regressions are visible.
- Smoke validation (agreed with user): 5-page canonical GPU run completes successfully with EasyOCR on MPS, acceptable coverage, and timing summary recorded. (20-page budget target deferred; user accepted 5-page smoke as sufficient.)
- Documentation describes prerequisites (Metal torch build), how to disable/force GPU, and how run_id generation works.

## Tasks
- [x] Detect MPS availability and enable EasyOCR reader with `gpu=True` when usable; keep CPU fallback.
- [x] Ensure required torch build is installed/selected; document install steps for Metal wheels.
- [x] Add per-run automatic run_id/output_dir generation (timestamped) by default, with an explicit flag to reuse a given run_id.
- [x] Add concise per-stage timing summary (wall seconds and pages/min for extract) emitted at end-of-run.
- [x] Validate on canonical GPU smoke (5 pages) with EasyOCR on MPS: record runtime, coverage, and regression check.
- [x] Update README/AGENTS with GPU usage, run_id defaults, and timing summary notes.

## Work Log
### 20251212-1755 — Docs updated for Metal GPU defaults
- **Result:** Success
- **Notes:** Added AGENTS/README guidance for creating the `codex-arm-mps` env with pinned Metal torch (2.9.1/0.24.1, Pillow<13), clarified GPU is default/pit-of-success, and noted benign MPS pin_memory warnings. Included quick sanity commands and smoke run pointers.
- **Next:** Run a 20-page GPU slice and capture coverage/timing; then update success criteria items 2/5/6.
### 20251212-1840 — Story closed after GPU smoke + regression check
- **Result:** Success
- **Notes:** Ran 5-page GPU smoke via `scripts/smoke_easyocr_gpu.sh`, intake on MPS (gpu:true) with timing summary; regression check script added and executed. Docs now default to `-c constraints/metal.txt` bootstrap and include one-shot smoke+check plus MPS troubleshooting. User confirmed 5-page smoke is sufficient in lieu of 20-page slice.
- **Next:** None; story marked Done.
### 20251211-1721 — Warmup uses MPS; torch pinned for Metal
- **Result:** Success (code + deps)
- **Notes:** EasyOCR warmup now passes the GPU flag so it initializes on MPS (removes misleading CPU warning). Pinned torch/torchvision (2.9.1/0.24.1) and relaxed Pillow constraint to <13 to match the Metal build for EasyOCR. This should make GPU the default “pit of success” on M-series.
- **Next:** Recreate env from requirements to confirm clean install; rerun 5-page EasyOCR-only smoke to verify warmup log shows gpu:true without CPU banner; update AGENTS/README with Metal install notes.
### 20251211-1205 — merge_ocr adapter contract fixed
- **Result:** Success (plumbing fix)
- **Notes:** `merge_ocr_escalated_v1` now declares `adapter_out` schema to match what it writes; recipe stamps `adapter_out.jsonl`. `reconstruct_text_v1` input schema switched to `adapter_out` (it already resolves `pagelines_final` inside). This unblocks downstream stages from merge_ocr onward.
- **Next:** Re-run canonical 20-page pipeline from `merge_ocr` using intake run `ff-canonical-mps-20-intake-20251211-104252`, verify boundary coverage now proceeds; then measure timing/coverage with GPU.

## Work Log
### 20251210-2039 — Story opened
- **Result:** Success (planning)
- **Notes:** Need to use M-series GPU via Metal torch for EasyOCR; currently CPU-only. Run_ids are reused, causing huge timelines; default should auto-generate. Also need timing summary to make perf tuning visible.
- **Next:** Implement GPU detect + reader flag, add auto run_id default/override, add timing summary, then run canonical 20-page on GPU.

### 20251210-2053 — Auto run_id/output_dir defaults added
- **Result:** Success (partial progress)
- **Notes:** Driver now auto-generates a unique run_id/output_dir unless `--allow-run-id-reuse` or explicit `--run-id` is provided. Reduces stale artifacts/log reuse. No GPU work yet.
- **Next:** Add MPS detection + `gpu=True` EasyOCR reader path, ensure Metal torch available, and add timing summary emission before rerunning canonical 20-page on GPU.

### 20251210-2055 — Timing summary emitted per run
- **Result:** Success
- **Notes:** Driver now records wall-seconds per stage and writes `timing_summary.json`; computes pages/min for intake/extract when artifacts exist. Printed to stdout as well. GPU work still pending.
- **Next:** Implement MPS detection + EasyOCR `gpu=True`, ensure Metal torch availability, then rerun canonical 20-page on GPU and update docs.

### 20251210-2056 — MPS detection + EasyOCR GPU flag wired
- **Result:** Success (code)
- **Notes:** `extract_ocr_ensemble_v1` now detects Metal (torch MPS) and passes `gpu=True` to EasyOCR reader when available, logging the gpu flag in debug events. Falls back to CPU otherwise. No run yet with Metal torch; installation/docs still pending.
- **Next:** Install/verify Metal torch on this host, rerun canonical 20-page with fresh run_id, capture timing summary and EasyOCR coverage, then document setup in README/AGENTS.

### 20251211-1330 — Merge fix + 20-page pipeline green (validation relaxed for smoke)
- **Result:** Success (pipeline completes)
- **Notes:** 
  - Fixed contract mismatch: `merge_ocr_escalated_v1` now declares `adapter_out`; `reconstruct_text_v1` input schema set to `adapter_out`; recipe stamps `adapter_out.jsonl`.
  - Relaxed smoke recipe expectations: boundary coverage/gate thresholds scaled to 20 pages; `validate_ff_engine` expected_range_end set to 1 to avoid false missing-section errors on slice; build now passes with stubs allowed.
  - Fixed `fine_segment_frontmatter_v1` temp issue (removed temperature arg) to avoid OpenAI 400 on new models.
  - Full 20-page run (run_id `ff-canonical-mps-20-intake-20251211-104252`) now completes through validate; timing_summary emitted. EasyOCR GPU path used if MPS available; needs Metal torch verification still.
- **Next:** Verify Metal torch install instructions, confirm MPS actually used during run (torch.backends.mps.is_available), and tighten validation thresholds once we run full-book; document changes in README/AGENTS.

### 20251211-1337 — Canonical restored to full-book defaults; smoke via overrides
- **Result:** Success (recipe reset)
- **Notes:** Reverted `recipe-ff-canonical.yaml` to full-book settings (end=113, min_present 320, gate 240, expected_range_end 400; stubs fail by default). Smoke runs should now be done via settings overrides (e.g., end=20, relaxed coverage/validate params) rather than baked-in lenient defaults. Keeps a single recipe while distinguishing “run” vs “correctness” by config.
- **Next:** Add a documented example override block (settings.smoke.yaml) and confirm full-book run after Metal torch install.

### 20251211-1345 — Smoke overrides added and run executed
- **Result:** Success (smoke run)
- **Notes:** Added `configs/settings.ff-canonical-smoke.yaml` (20-page slice, relaxed coverage/gate/validate, allow-stubs). Updated README/AGENTS to point to this single smoke path. Ran smoke with `--settings configs/settings.ff-canonical-smoke.yaml` (SHM env + escalated) → pipeline completed; timing_summary written; warnings only (expected given hallucinated 401 stubs). Run artifacts at `output/runs/ff-canonical/` (auto run_id reused per recipe).
- **Next:** Verify Metal torch/MPS availability; separate full-book run with GPU; tighten warnings by improving intake quality (reduce hallucinated sections) when not in smoke mode.
